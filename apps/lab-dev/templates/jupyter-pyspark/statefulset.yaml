apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: jupyter-pyspark
  labels:
    app: jupyter-pyspark
spec:
  serviceName: jupyter-pyspark
  replicas: 1
  selector:
    matchLabels:
      app: jupyter-pyspark
  template:
    metadata:
      labels:
        app: jupyter-pyspark
    spec:
      initContainers:
        - name: download-jars
          image: curlimages/curl:latest
          command:
            - sh
            - -c
            - |
              set -e
              hadoop_version="3.3.4"

              curl -L -o /extra-jars/aws-java-sdk-bundle-1.12.262.jar https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar
              curl -L -o /extra-jars/hadoop-aws-$hadoop_version.jar https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/$hadoop_version/hadoop-aws-$hadoop_version.jar
          volumeMounts:
            - name: extra-spark-jars
              mountPath: /extra-jars
      containers:
        - name: jupyter-pyspark
          image: quay.io/jupyter/pyspark-notebook:spark-3.5.3
          ports:
            - containerPort: 8888
              name: jupyter
          volumeMounts:
            - name: data
              mountPath: /home/jovyan/work
            - name: extra-spark-jars
              mountPath: /extra-jars
          resources:
            requests:
              cpu: "250m"
              memory: "1Gi"
            limits:
              cpu: "1000m"
              memory: "2Gi"
      volumes:
        - name: extra-spark-jars
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 1Gi
